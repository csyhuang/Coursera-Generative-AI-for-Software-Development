
# Question 1
What do you call the commonly used AI technology for learning input (A) to output (B) mappings?


Unsupervised learning
Generative AI
- [x] Supervised learning
Reinforcement learning


# Question 2
Which of the following are examples of tasks that could be performed by supervised learning models?


- [ ] Writing a reply to an email
- [x] Deciding if a user will click on an online advertisement
- [x] Determining whether a medical image indicates disease or not
- [x] Deciding if a product review is positive or negative


# Question 3
In the example about retinal image classification, Laurence mentioned that a supervised learning model learned to predict additional relationships between data points beyond the disease state, like the sex of the patient. What does this suggest about supervised learning?


- [ ] The model has become sentient and can think for itself.
- [ ] The model is overfitting the training data by finding unnecessary patterns.
- [x] The model can identify broader patterns and relationships in the training data.
- [ ] The model can only predict the original target labels of the data it was trained on.


# Question 4
Which of these is the most accurate description of an LLM?
- [ ] It generates text by finding a writing partner to work with you
- [ ] It generates text by using supervised learning to carry out web search
- [x] It generates text by repeatedly predicting the next word
- [ ] It generates text by repeatedly predicting words in random order

# Question 5
How does the attention mechanism of a transformer work? 


- [ ] It searches existing sources of text to determine the most probable next word
- [ ] It maps input to output tokens using unsupervised learning
- [x] It allows the model to focus on specific words when predicting the next word
- [x] It adjusts the vector embeddings of tokens to account for the surrounding words


